{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ8ChHU8HsKm"
      },
      "source": [
        "#Setting up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfiJAxLxBfNA"
      },
      "source": [
        "## Mounting drive and Installing SAM 2 on Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Yq09Fn7KfMA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtyCh1Uzl6DP"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/facebookresearch/sam2.git\n",
        "%cd /content/sam2\n",
        "!pip install -q -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Za0Bh3cBw2b"
      },
      "source": [
        "## Downloading checkpoints (use first for the baseline models and the second for the finetuned models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM6KDUGfqkDO"
      },
      "outputs": [],
      "source": [
        "!wget -O sam2.1_hiera_large.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\"\n",
        "!wget -O sam2.1_hiera_base_plus.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAPQBwe6MRno"
      },
      "outputs": [],
      "source": [
        "!cd ./checkpoints && ./download_ckpts.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cubg7hc_Bz-b"
      },
      "source": [
        "## Device and importing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_BACLiPWvh6R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# select the device for computation\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yHvoJtPd_BF"
      },
      "source": [
        "## SAM2 model initiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySa8GmEEsVTj"
      },
      "source": [
        "###For Hiera base plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4AQ7zrXhd_nN"
      },
      "outputs": [],
      "source": [
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "\n",
        "## For hiera base plus\n",
        "checkpoint = \"/content/sam2/checkpoints/sam2.1_hiera_base_plus.pt\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
        "\n",
        "sam2_model = build_sam2(model_cfg, checkpoint, device=device)\n",
        "predictor = SAM2ImagePredictor(sam2_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiUBeVvjsTxw"
      },
      "source": [
        "###For Hiera large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXT_yUVRsOGr"
      },
      "outputs": [],
      "source": [
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "\n",
        "## For hiera base plus\n",
        "checkpoint = \"/content/sam2/checkpoints/sam2.1_hiera_large.pt\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "\n",
        "sam2_model = build_sam2(model_cfg, checkpoint, device=device)\n",
        "predictor = SAM2ImagePredictor(sam2_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0K9B1eyHmMP"
      },
      "source": [
        "#Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPzJ0rVcB_uo"
      },
      "source": [
        "##Utility functions for loading data and processing images and masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cNrWazVjwWwE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from threading import Lock\n",
        "from google.colab import files\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Utility Functions\n",
        "def load_csv(csv_path):\n",
        "    \"\"\"\n",
        "    Load the frame and mask paths from a CSV file,\n",
        "    and prepend the base dataset path to construct full paths.\n",
        "    \"\"\"\n",
        "    base_dir = \"/content/drive/MyDrive/CV/SAM2/Datasets\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Add base_dir to the paths in the CSV\n",
        "    frame_paths = [os.path.join(base_dir, path) for path in df['frame']]\n",
        "    mask_paths = [os.path.join(base_dir, path) for path in df['mask']]\n",
        "\n",
        "    return mask_paths, frame_paths\n",
        "\n",
        "def load_image(image_path):\n",
        "    \"\"\"Load an image in RGB format.\"\"\"\n",
        "    if os.path.exists(image_path):\n",
        "        return np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "    return None\n",
        "\n",
        "def load_mask(mask_path):\n",
        "    \"\"\"Load a mask in grayscale format.\"\"\"\n",
        "    if os.path.exists(mask_path):\n",
        "        return np.array(Image.open(mask_path).convert(\"L\"))\n",
        "    return None\n",
        "\n",
        "def select_point_prompt(mask, num_points=1):\n",
        "    \"\"\"Select points and labels from the mask where the mask value is 255.\"\"\"\n",
        "    coordinates = np.argwhere(mask == 255)\n",
        "    if len(coordinates) < num_points:\n",
        "        return None, None\n",
        "    selected_indices = np.random.choice(len(coordinates), num_points, replace=False)\n",
        "    points = [tuple(coordinates[i][::-1]) for i in selected_indices]  # Convert (y, x) to (x, y)\n",
        "    labels = [1] * num_points\n",
        "    return points, labels\n",
        "\n",
        "# Create a global lock for shared resources\n",
        "predictor_lock = Lock()\n",
        "output_lock = Lock()\n",
        "\n",
        "def process_single_image(predictor, image_path, mask_path, num_points, output_dir):\n",
        "    \"\"\"Process a single image-mask pair to generate and save the predicted mask.\n",
        "    Args:\n",
        "    - predictor: The SAM2 predictor instance.\n",
        "    - image_path: Path to the frame image.\n",
        "    - mask_path: Path to the mask image.\n",
        "    - num_points: Number of points to sample for prediction.\n",
        "    - output_dir: Directory to save predicted masks.\n",
        "    \"\"\"\n",
        "    print(f\"Processing frame: {image_path}, mask: {mask_path}\")\n",
        "    image = load_image(image_path)\n",
        "    mask = load_mask(mask_path)\n",
        "    if image is None or mask is None:\n",
        "        print(f\"Error: Could not load image or mask for {image_path} or {mask_path}\")\n",
        "        return\n",
        "\n",
        "    points, labels = select_point_prompt(mask, num_points=num_points)\n",
        "    if points is None:\n",
        "        print(f\"No valid points found in mask: {mask_path}\")\n",
        "        return\n",
        "\n",
        "    with predictor_lock:  # Lock shared predictor during access\n",
        "        predictor.set_image(image)\n",
        "        with torch.no_grad():\n",
        "            masks, scores, logits = predictor.predict(\n",
        "                point_coords=np.array(points),\n",
        "                point_labels=np.array(labels),\n",
        "                multimask_output=False  # Ensures a single mask is returned\n",
        "            )\n",
        "\n",
        "    predicted_mask = (masks[0] > 0.5).astype(np.uint8) * 255  # Convert to binary mask\n",
        "\n",
        "    masks_relative_path = mask_path.split(\"Masks/\")[-1]\n",
        "    output_path = os.path.join(output_dir, masks_relative_path)\n",
        "    with output_lock:  # Thread-safe access to shared directories\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "    # Step 6: Save the predicted mask\n",
        "    with output_lock:  # Ensure only one thread writes to the file system at a time\n",
        "        cv2.imwrite(output_path, predicted_mask)\n",
        "\n",
        "def process_image_wrapper(args):\n",
        "    \"\"\"\n",
        "    Wrapper function to handle arguments for parallel processing.\n",
        "    Args is a tuple containing:\n",
        "    - predictor: The SAM2 predictor instance.\n",
        "    - image_path: Path to the frame image.\n",
        "    - mask_path: Path to the mask image.\n",
        "    - num_points: Number of points to sample for prediction.\n",
        "    - output_dir: Directory to save predicted masks.\n",
        "    \"\"\"\n",
        "    predictor, image_path, mask_path, num_points, output_dir = args\n",
        "    process_single_image(predictor, image_path, mask_path, num_points, output_dir)\n",
        "\n",
        "\n",
        "def process_dataset_parallel(predictor, dataset_name, dataset_type=\"val\", num_points=1, max_workers=4):\n",
        "    \"\"\"\n",
        "    Process all images and masks in a dataset to generate predicted masks using parallel processing.\n",
        "    \"\"\"\n",
        "    # Define paths\n",
        "    csv_path = f\"/content/drive/MyDrive/CV/SAM2/Datasets/Paths/{dataset_name}_{dataset_type}.csv\"\n",
        "    output_dir = f\"/content/drive/MyDrive/CV/SAM2/Datasets/{dataset_name}/{dataset_type}/PredictedMasks\"\n",
        "\n",
        "    # Load CSV\n",
        "    mask_paths, frame_paths = load_csv(csv_path)\n",
        "    print(\"Loaded frame paths:\", frame_paths)\n",
        "    print(\"Loaded mask paths:\", mask_paths)\n",
        "\n",
        "    # Prepare arguments for parallel processing\n",
        "    args_list = [\n",
        "        (predictor, frame_path, mask_path, num_points, output_dir)\n",
        "        for frame_path, mask_path in zip(frame_paths, mask_paths)\n",
        "    ]\n",
        "    print(f\"Output dir: {output_dir}\")\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel processing\n",
        "    print(f\"Starting parallel processing for dataset: {dataset_name} with {max_workers} workers\")\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        executor.map(process_image_wrapper, args_list)\n",
        "    print(f\"Completed processing dataset: {dataset_name}\")\n",
        "\n",
        "# Main Function\n",
        "def main_with_image_predictor_parallel(dataset_name=None, dataset_type=\"val\", num_points=1, device=device, model_cfg=model_cfg, checkpoint=checkpoint, max_workers=4):\n",
        "    \"\"\"\n",
        "    Main entry point for processing datasets with the SAM2 predictor using parallel processing.\n",
        "\n",
        "    Args:\n",
        "        dataset_name (str): Name of the dataset to process.\n",
        "        dataset_type (str): Subset to process (\"train\", \"val\", \"test\"). Default is \"val\".\n",
        "        num_points (int): Number of points to sample from the mask.\n",
        "        device (str): Device to use for model inference (\"cpu\" or \"cuda\").\n",
        "        checkpoint (str): Path to the SAM2 model checkpoint.\n",
        "        max_workers (int): Number of workers for parallel processing.\n",
        "    \"\"\"\n",
        "    if checkpoint is None:\n",
        "        raise ValueError(\"Checkpoint path must be provided.\")\n",
        "\n",
        "    # Build and initialize the SAM2 model\n",
        "    sam2_model = build_sam2(model_cfg, checkpoint, device=device)\n",
        "    predictor = SAM2ImagePredictor(sam2_model)\n",
        "\n",
        "    if dataset_name:\n",
        "        # Process the specified dataset\n",
        "        process_dataset_parallel(predictor, dataset_name, dataset_type, num_points, max_workers=max_workers)\n",
        "    else:\n",
        "        # Process all datasets if no specific dataset is provided\n",
        "        datasets = [\"Endoscapes\", \"UD Ureter-Uterine Artery-Nerve Dataset\", \"CholecSeg8k\", \"m2caiSeg\", \"Dresden\"]\n",
        "        for dataset in datasets:\n",
        "            process_dataset_parallel(predictor, dataset, dataset_type, num_points, max_workers=max_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gevltrOIIPzL"
      },
      "source": [
        "##Utility functions for Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jzTMrrqul6jf"
      },
      "outputs": [],
      "source": [
        "# Utility Functions for Metrics Calculation\n",
        "def calculate_metrics(predicted_mask, ground_truth_mask):\n",
        "    \"\"\"\n",
        "    Calculate IoU, Dice, Precision, and Recall metrics.\n",
        "\n",
        "    Parameters:\n",
        "    - predicted_mask: Binary mask of the predicted segmentation.\n",
        "    - ground_truth_mask: Binary mask of the ground truth segmentation.\n",
        "\n",
        "    Returns:\n",
        "    - IoU, Dice, Precision, Recall metrics.\n",
        "    \"\"\"\n",
        "    # Ensure the masks are valid\n",
        "    if predicted_mask is None or ground_truth_mask is None:\n",
        "        raise ValueError(\"One of the masks is None.\")\n",
        "\n",
        "    # Handle extra dimensions\n",
        "    if len(predicted_mask.shape) > 2 and predicted_mask.shape[-1] == 1:\n",
        "        predicted_mask = predicted_mask.squeeze(-1)\n",
        "    if len(ground_truth_mask.shape) > 2 and ground_truth_mask.shape[-1] == 1:\n",
        "        ground_truth_mask = ground_truth_mask.squeeze(-1)\n",
        "\n",
        "    # Resize if dimensions mismatch\n",
        "    if predicted_mask.shape != ground_truth_mask.shape:\n",
        "        predicted_mask = cv2.resize(predicted_mask, (ground_truth_mask.shape[1], ground_truth_mask.shape[0]))\n",
        "\n",
        "    # Convert masks to binary\n",
        "    predicted_mask_bin = (predicted_mask > 127).astype(np.uint8)\n",
        "    ground_truth_bin = (ground_truth_mask > 127).astype(np.uint8)\n",
        "\n",
        "    # Calculate metrics\n",
        "    intersection = np.logical_and(predicted_mask_bin, ground_truth_bin).sum()\n",
        "    union = np.logical_or(predicted_mask_bin, ground_truth_bin).sum()\n",
        "    predicted_sum = predicted_mask_bin.sum()\n",
        "    ground_truth_sum = ground_truth_bin.sum()\n",
        "\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "    dice = (2 * intersection) / (predicted_sum + ground_truth_sum) if (predicted_sum + ground_truth_sum) > 0 else 0\n",
        "    precision = intersection / predicted_sum if predicted_sum > 0 else 0\n",
        "    recall = intersection / ground_truth_sum if ground_truth_sum > 0 else 0\n",
        "\n",
        "    return iou, dice, precision, recall\n",
        "\n",
        "\n",
        "def evaluate_dataset(predicted_masks_path, ground_truth_masks_path):\n",
        "    \"\"\"\n",
        "    Evaluate predicted masks against ground truth masks for a specific class,\n",
        "    preserving the exact folder structure matching.\n",
        "\n",
        "    Parameters:\n",
        "    - predicted_masks_path: Path to the folder containing predicted masks\n",
        "    - ground_truth_masks_path: Path to the folder containing ground truth masks\n",
        "\n",
        "    Returns:\n",
        "    - A list of dictionaries with evaluation metrics for each file\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    valid_extensions = ('.png', '.jpg', '.jpeg')\n",
        "\n",
        "    # Walk through the predicted masks directory\n",
        "    for root, _, files in os.walk(predicted_masks_path):\n",
        "        for file in files:\n",
        "            if not file.lower().endswith(valid_extensions):\n",
        "                continue\n",
        "\n",
        "            # Get the relative path from the predicted_masks_path\n",
        "            rel_path = os.path.relpath(root, predicted_masks_path)\n",
        "\n",
        "            # Construct the corresponding ground truth path\n",
        "            gt_root = os.path.join(ground_truth_masks_path, rel_path)\n",
        "            gt_path = os.path.join(gt_root, file)\n",
        "            pred_path = os.path.join(root, file)\n",
        "\n",
        "            if not os.path.exists(gt_path):\n",
        "                print(f\"Missing ground truth for: {os.path.join(rel_path, file)}\")\n",
        "                continue\n",
        "\n",
        "            predicted_mask = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
        "            ground_truth_mask = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if predicted_mask is None or ground_truth_mask is None:\n",
        "                print(f\"Error loading masks for: {os.path.join(rel_path, file)}\")\n",
        "                continue\n",
        "\n",
        "            iou, dice, precision, recall = calculate_metrics(predicted_mask, ground_truth_mask)\n",
        "            results.append({\n",
        "                \"File\": os.path.join(rel_path, file),  # Store full relative path\n",
        "                \"IoU\": iou,\n",
        "                \"Dice\": dice,\n",
        "                \"Precision\": precision,\n",
        "                \"Recall\": recall\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def evaluate_all_datasets(base_dir, subset=\"val\", datasets=None):\n",
        "    \"\"\"\n",
        "    Evaluate specified or all datasets for IoU, Dice, Precision, and Recall,\n",
        "    preserving the exact folder structure matching between predicted and ground truth masks.\n",
        "\n",
        "    Parameters:\n",
        "    - base_dir: Base directory containing datasets\n",
        "    - subset: Subset to evaluate (e.g., 'val')\n",
        "    - datasets: List of dataset names or None to evaluate all datasets in base_dir\n",
        "\n",
        "    Returns:\n",
        "    - A DataFrame containing evaluation metrics for all datasets and classes\n",
        "    \"\"\"\n",
        "    if datasets is None:\n",
        "        datasets = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
        "\n",
        "    all_results = []\n",
        "    for dataset in datasets:\n",
        "        print(f\"\\nEvaluating dataset: {dataset}\")\n",
        "\n",
        "        predicted_masks_base = os.path.join(base_dir, dataset, subset, \"PredictedMasks\")\n",
        "        ground_truth_masks_base = os.path.join(base_dir, dataset, subset, \"Masks\")\n",
        "\n",
        "        if not os.path.exists(predicted_masks_base):\n",
        "            print(f\"Predicted masks folder not found for {dataset}: {predicted_masks_base}\")\n",
        "            continue\n",
        "        if not os.path.exists(ground_truth_masks_base):\n",
        "            print(f\"Ground truth masks folder not found for {dataset}: {ground_truth_masks_base}\")\n",
        "            continue\n",
        "\n",
        "        # Get classes (top-level folders in ground truth masks)\n",
        "        classes = [\n",
        "            d for d in os.listdir(ground_truth_masks_base)\n",
        "            if os.path.isdir(os.path.join(ground_truth_masks_base, d))\n",
        "        ]\n",
        "\n",
        "        dataset_results = []\n",
        "        for class_name in classes:\n",
        "            print(f\"  Evaluating class: {class_name}\")\n",
        "\n",
        "            predicted_masks_path = os.path.join(predicted_masks_base, class_name)\n",
        "            ground_truth_masks_path = os.path.join(ground_truth_masks_base, class_name)\n",
        "\n",
        "            if not os.path.exists(predicted_masks_path):\n",
        "                print(f\"    Predicted masks for class '{class_name}' not found.\")\n",
        "                continue\n",
        "            if not os.path.exists(ground_truth_masks_path):\n",
        "                print(f\"    Ground truth masks for class '{class_name}' not found.\")\n",
        "                continue\n",
        "\n",
        "            results = evaluate_dataset(predicted_masks_path, ground_truth_masks_path)\n",
        "            for result in results:\n",
        "                result[\"Dataset\"] = dataset\n",
        "                result[\"Class\"] = class_name\n",
        "            dataset_results.extend(results)\n",
        "\n",
        "        if not dataset_results:\n",
        "            print(f\"No results found for dataset: {dataset}\")\n",
        "            continue\n",
        "\n",
        "        dataset_results_df = pd.DataFrame(dataset_results)\n",
        "\n",
        "        dataset_summary_per_class = dataset_results_df.groupby(\"Class\").agg(\n",
        "            mean_IoU=(\"IoU\", \"mean\"),\n",
        "            sd_IoU=(\"IoU\", \"std\"),\n",
        "            mean_Dice=(\"Dice\", \"mean\"),\n",
        "            sd_Dice=(\"Dice\", \"std\"),\n",
        "            mean_Precision=(\"Precision\", \"mean\"),\n",
        "            sd_Precision=(\"Precision\", \"std\"),\n",
        "            mean_Recall=(\"Recall\", \"mean\"),\n",
        "            sd_Recall=(\"Recall\", \"std\"),\n",
        "        ).reset_index()\n",
        "\n",
        "        dataset_overall_summary = pd.DataFrame({\n",
        "            \"Metric\": [\"IoU\", \"Dice\", \"Precision\", \"Recall\"],\n",
        "            \"Mean\": [\n",
        "                dataset_results_df[\"IoU\"].mean(),\n",
        "                dataset_results_df[\"Dice\"].mean(),\n",
        "                dataset_results_df[\"Precision\"].mean(),\n",
        "                dataset_results_df[\"Recall\"].mean(),\n",
        "            ],\n",
        "            \"SD\": [\n",
        "                dataset_results_df[\"IoU\"].std(),\n",
        "                dataset_results_df[\"Dice\"].std(),\n",
        "                dataset_results_df[\"Precision\"].std(),\n",
        "                dataset_results_df[\"Recall\"].std(),\n",
        "            ]\n",
        "        })\n",
        "\n",
        "        # Save results\n",
        "        eval_results_dir = os.path.join(base_dir, \"Eval_Results\")\n",
        "        os.makedirs(eval_results_dir, exist_ok=True)\n",
        "\n",
        "        results_csv_path = os.path.join(eval_results_dir, f\"{dataset}_evaluation_metrics_all_datasets_classes.csv\")\n",
        "        summary_csv_path = os.path.join(eval_results_dir, f\"{dataset}_evaluation_summary_per_class.csv\")\n",
        "        overall_csv_path = os.path.join(eval_results_dir, f\"{dataset}_evaluation_overall_summary.csv\")\n",
        "\n",
        "        dataset_results_df.to_csv(results_csv_path, index=False)\n",
        "        dataset_summary_per_class.to_csv(summary_csv_path, index=False)\n",
        "        dataset_overall_summary.to_csv(overall_csv_path, index=False)\n",
        "\n",
        "        print(f\"\\nSaved evaluation results for dataset '{dataset}' to {results_csv_path}\")\n",
        "        print(f\"Saved per-class summary for dataset '{dataset}' to {summary_csv_path}\")\n",
        "        print(f\"Saved overall summary for dataset '{dataset}' to {overall_csv_path}\")\n",
        "\n",
        "    return pd.DataFrame(all_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gTBtJLW0aja"
      },
      "source": [
        "##Utility functions for zipping, downloading, and deleting - Predicted Masks folders and Eval results from all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fbz4BRQB0bHJ"
      },
      "outputs": [],
      "source": [
        "def zip_folder(folder_path, zip_path):\n",
        "    \"\"\"\n",
        "    Compress a folder into a zip file and save it to the specified path.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the folder to compress.\n",
        "        zip_path (str): Path where the zip file will be saved (including filename).\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the created zip file or None if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create the zip file\n",
        "        shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', folder_path)\n",
        "        print(f\"Compressed folder: {folder_path} into zip: {zip_path}\")\n",
        "        return zip_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error while zipping folder {folder_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def download_file_colab(file_path):\n",
        "    \"\"\"\n",
        "    Download a file from Colab to your local computer.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file in Colab to be downloaded.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            files.download(file_path)\n",
        "            print(f\"File downloaded: {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during download: {e}\")\n",
        "    else:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "\n",
        "\n",
        "def delete_zip_files(file_paths):\n",
        "    \"\"\"\n",
        "    Delete the specified zip files.\n",
        "\n",
        "    Args:\n",
        "        file_paths (list): List of file paths to delete.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    for file_path in file_paths:\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                print(f\"Deleted file: {file_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error while deleting file {file_path}: {e}\")\n",
        "        else:\n",
        "            print(f\"File not found: {file_path}\")\n",
        "\n",
        "\n",
        "def compress_and_download_predicted_masks(base_dir, datasets, subset=\"val\"):\n",
        "    \"\"\"\n",
        "    Compress and download the PredictedMasks folders into zip files.\n",
        "\n",
        "    Args:\n",
        "        base_dir (str): Base directory containing the datasets.\n",
        "        datasets (list): List of dataset names to process.\n",
        "        subset (str): Dataset subset to process (e.g., \"val\").\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    for dataset in datasets:\n",
        "        # Path to the PredictedMasks folder\n",
        "        predicted_masks_dir = os.path.join(base_dir, dataset, subset, \"PredictedMasks\")\n",
        "\n",
        "        if not os.path.exists(predicted_masks_dir):\n",
        "            print(f\"PredictedMasks folder not found: {predicted_masks_dir} for dataset: {dataset}\")\n",
        "            continue\n",
        "\n",
        "        # Set the zip filename with special handling for \"UD Ureter-Uterine Artery-Nerve Dataset\"\n",
        "        if dataset == \"UD Ureter-Uterine Artery-Nerve Dataset\":\n",
        "            zip_filename = \"UDUreter_PredictedMasks.zip\"\n",
        "        else:\n",
        "            zip_filename = f\"{dataset.replace(' ', '_')}_PredictedMasks.zip\"\n",
        "\n",
        "        zip_path = os.path.join(base_dir, zip_filename)\n",
        "\n",
        "        # Compress the folder\n",
        "        zip_folder(predicted_masks_dir, zip_path)\n",
        "\n",
        "        # Trigger download\n",
        "        download_file_colab(zip_path)\n",
        "        print(f\"Successfully downloaded zip for dataset: {dataset}\")\n",
        "\n",
        "\n",
        "def download_all_eval_results(eval_results_dir):\n",
        "    \"\"\"\n",
        "    Compress and download the evaluation results from the specified directory.\n",
        "\n",
        "    Args:\n",
        "        eval_results_dir (str): Path to the directory containing all evaluation results.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if not os.path.exists(eval_results_dir):\n",
        "        print(f\"Eval_Results directory not found: {eval_results_dir}\")\n",
        "        return\n",
        "\n",
        "    # Define the output zip file path\n",
        "    zip_filename = \"Eval_Results.zip\"\n",
        "    zip_path = os.path.join(eval_results_dir, \"..\", zip_filename)\n",
        "\n",
        "    # Compress the folder\n",
        "    zip_folder(eval_results_dir, zip_path)\n",
        "\n",
        "    # Trigger download\n",
        "    download_file_colab(zip_path)\n",
        "    print(\"Successfully downloaded evaluation results zip file.\")\n",
        "\n",
        "\n",
        "# Function for deleting folders\n",
        "\n",
        "def delete_predicted_masks(base_dir, datasets, subset=\"val\"):\n",
        "    \"\"\"\n",
        "    Delete all PredictedMasks folders for the specified datasets.\n",
        "\n",
        "    Args:\n",
        "        base_dir (str): Base directory containing the datasets.\n",
        "        datasets (list): List of dataset names.\n",
        "        subset (str): Subset folder where PredictedMasks is located (e.g., \"val\").\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    for dataset in datasets:\n",
        "        predicted_masks_dir = os.path.join(base_dir, dataset, subset, \"PredictedMasks\")\n",
        "\n",
        "        if os.path.exists(predicted_masks_dir):\n",
        "            shutil.rmtree(predicted_masks_dir)\n",
        "            print(f\"Deleted PredictedMasks folder for dataset: {dataset}\")\n",
        "        else:\n",
        "            print(f\"PredictedMasks folder not found for dataset: {dataset}\")\n",
        "\n",
        "\n",
        "def delete_eval_results(eval_results_dir):\n",
        "    \"\"\"\n",
        "    Delete the Eval_Results folder.\n",
        "\n",
        "    Args:\n",
        "        eval_results_dir (str): Path to the Eval_Results directory.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if os.path.exists(eval_results_dir):\n",
        "        shutil.rmtree(eval_results_dir)\n",
        "        print(f\"Deleted Eval_Results folder: {eval_results_dir}\")\n",
        "    else:\n",
        "        print(f\"Eval_Results folder not found: {eval_results_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBI4oeh7ahtq"
      },
      "source": [
        "# Baseline model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6oiB2ToHSW5"
      },
      "source": [
        "###Function for automating the eval pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I1HD7yxzaiBQ"
      },
      "outputs": [],
      "source": [
        "def run_pipeline(num_points=1, checkpoint=checkpoint, dataset_type=\"val\", device=device, threads=4):\n",
        "    \"\"\"\n",
        "    Run the full pipeline for processing datasets, evaluating results,\n",
        "    compressing and downloading results, and cleaning up files.\n",
        "\n",
        "    Args:\n",
        "        num_points (int): Number of points for prediction.\n",
        "        checkpoint (str): Checkpoint for the predictor.\n",
        "        device (str): Device to use for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Dataset names\n",
        "    datasets = [\"UD Ureter-Uterine Artery-Nerve Dataset\", \"m2caiSeg\", \"Endoscapes\", \"Dresden\", \"CholecSeg8k\"]\n",
        "\n",
        "    # Dataset names\n",
        "    #datasets = [\"ARTNet\"]\n",
        "\n",
        "    base_dir = \"/content/drive/MyDrive/CV/SAM2/Datasets\"\n",
        "    eval_results_dir = os.path.join(base_dir, \"Eval_Results\")\n",
        "\n",
        "    # Error log\n",
        "    error_log = []\n",
        "\n",
        "    # Step 1: Run main_with_image_predictor for all datasets\n",
        "    for dataset_name in datasets:\n",
        "        try:\n",
        "            print(f\"Processing dataset: {dataset_name}\")\n",
        "            main_with_image_predictor_parallel(\n",
        "                dataset_name=dataset_name,\n",
        "                dataset_type=dataset_type,\n",
        "                num_points=num_points,\n",
        "                device=device,\n",
        "                checkpoint=checkpoint,\n",
        "                max_workers=threads\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_message = f\"Error during main_with_image_predictor for dataset {dataset_name}: {str(e)}\"\n",
        "            print(error_message)\n",
        "            error_log.append(error_message)\n",
        "\n",
        "    # Step 2: Evaluate results for all datasets\n",
        "    for dataset_name in datasets:\n",
        "        try:\n",
        "            print(f\"Evaluating dataset: {dataset_name}\")\n",
        "            results_df = evaluate_all_datasets(\n",
        "                base_dir=base_dir,\n",
        "                subset=dataset_type,\n",
        "                datasets=[dataset_name]\n",
        "            )\n",
        "            print(f\"Evaluation complete for dataset: {dataset_name}\")\n",
        "        except Exception as e:\n",
        "            error_message = f\"Error during evaluation for dataset {dataset_name}: {str(e)}\"\n",
        "            print(error_message)\n",
        "            error_log.append(error_message)\n",
        "\n",
        "    # Step 3: Compress and download evaluation results\n",
        "    try:\n",
        "        print(\"Compressing and downloading evaluation results...\")\n",
        "        download_all_eval_results(eval_results_dir)\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error during compressing and downloading evaluation results: {str(e)}\"\n",
        "        print(error_message)\n",
        "        error_log.append(error_message)\n",
        "\n",
        "    # Step 4: Compress predicted masks (optional if required)\n",
        "    try:\n",
        "        print(\"Compressing predicted masks...\")\n",
        "        compress_and_download_predicted_masks(base_dir, datasets, subset=dataset_type)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error during compressing predicted masks: {str(e)}\"\n",
        "        print(error_message)\n",
        "        error_log.append(error_message)\n",
        "\n",
        "    # Print the error log at the end\n",
        "    if error_log:\n",
        "        print(\"\\n=== Error Log ===\")\n",
        "        for error in error_log:\n",
        "            print(error)\n",
        "    else:\n",
        "        print(\"Pipeline execution complete without errors.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk-eh6LGHYIF"
      },
      "source": [
        "###Running eval pipeline with baseline Hiera large and Hiera Base plus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XxJJoPiOAZo"
      },
      "source": [
        "For Hiera Large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKvCixEmNcFs"
      },
      "outputs": [],
      "source": [
        "## For hiera large\n",
        "sam2_checkpoint = \"/content/sam2/checkpoints/sam2.1_hiera_large.pt\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
        "predictor = SAM2ImagePredictor(sam2_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq9SkbUVOCi3"
      },
      "source": [
        "For Hiera Base Plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV6QL59gN07a"
      },
      "outputs": [],
      "source": [
        "## For hiera base plus\n",
        "sam2_checkpoint = \"/content/sam2/checkpoints/sam2.1_hiera_base_plus.pt\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
        "\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
        "predictor = SAM2ImagePredictor(sam2_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZWqQT88aouz"
      },
      "outputs": [],
      "source": [
        "# Run the pipeline\n",
        "run_pipeline(num_points=10, checkpoint=sam2_checkpoint, dataset_type=\"test\", device=device, threads=16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-cOUyV2ECF0"
      },
      "source": [
        "##Delete all the PredictedMasks and Zip files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i2PyapdBTGW"
      },
      "outputs": [],
      "source": [
        "base_dir = \"/content/drive/MyDrive/CV/SAM2/Datasets\"\n",
        "datasets = [\"UD Ureter-Uterine Artery-Nerve Dataset\", \"Dresden\", \"Endoscapes\", \"m2caiSeg\", \"CholecSeg8k\"]\n",
        "eval_results_dir = \"/content/drive/MyDrive/CV/SAM2/Datasets/Eval_Results\"\n",
        "\n",
        "\n",
        "# List of specific zip files to delete\n",
        "zip_files_to_delete_masks = [\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/CholecSeg8k_PredictedMasks.zip\",\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/Dresden_PredictedMasks.zip\",\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/Endoscapes_PredictedMasks.zip\",\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/UDUreter_PredictedMasks.zip\",\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/m2caiSeg_PredictedMasks.zip\",\n",
        "]\n",
        "\n",
        "zip_files_to_delete_eval = [\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/Eval_Results.zip\"\n",
        "]\n",
        "\n",
        "print(\"Deleting predicted masks zip files...\")\n",
        "delete_zip_files(zip_files_to_delete_masks)\n",
        "\n",
        "print(\"Deleting PredictedMasks folders...\")\n",
        "delete_predicted_masks(base_dir, datasets, subset=\"val\")\n",
        "\n",
        "print(\"Deleting Eval_Results folder...\")\n",
        "delete_eval_results(eval_results_dir)\n",
        "\n",
        "# Delete the zip file\n",
        "delete_zip_files(zip_files_to_delete_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4sKYOpk21r8"
      },
      "source": [
        "#Fine-tuned model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmhCxbpTVRoe"
      },
      "source": [
        "##Eval pipeline with chosen fine-tuned checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o8HH7p8aAo_d"
      },
      "outputs": [],
      "source": [
        "def main_with_finetuned_image_predictor_parallel(\n",
        "    predictor,\n",
        "    dataset_name=None,\n",
        "    dataset_type=\"val\",\n",
        "    num_points=1,\n",
        "    max_workers=16\n",
        "):\n",
        "    \"\"\"\n",
        "    Main entry point for processing datasets with the SAM2 predictor using a preloaded fine-tuned model and parallel processing.\n",
        "\n",
        "    Args:\n",
        "        predictor (SAM2ImagePredictor): Preloaded SAM2ImagePredictor with fine-tuned weights.\n",
        "        dataset_name (str): Name of the dataset to process.\n",
        "        dataset_type (str): Subset to process (\"train\", \"val\", \"test\"). Default is \"val\".\n",
        "        num_points (int): Number of points to sample from the mask.\n",
        "        max_workers (int): Number of workers for parallel processing.\n",
        "    \"\"\"\n",
        "    if dataset_name:\n",
        "        # Process the specified dataset\n",
        "        process_dataset_parallel(predictor, dataset_name, dataset_type, num_points, max_workers=max_workers)\n",
        "    else:\n",
        "        # Process all datasets if no specific dataset is provided\n",
        "        datasets = [\"Endoscapes\", \"UD Ureter-Uterine Artery-Nerve Dataset\", \"CholecSeg8k\", \"m2caiSeg\", \"Dresden\"]\n",
        "        for dataset in datasets:\n",
        "            process_dataset_parallel(predictor, dataset, dataset_type, num_points, max_workers=max_workers)\n",
        "\n",
        "\n",
        "def run_pipeline_finetuned_model(num_points=1, dataset_type=\"val\", predictor=None, threads=16):\n",
        "    \"\"\"\n",
        "    Run the full pipeline for processing datasets, evaluating results,\n",
        "    compressing and downloading results, and cleaning up files.\n",
        "\n",
        "    Args:\n",
        "        num_points (int): Number of points for prediction.\n",
        "        predictor (SAM2ImagePredictor): Preloaded predictor with fine-tuned weights.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    import time\n",
        "    import os\n",
        "\n",
        "    # Dataset names\n",
        "    datasets = [\n",
        "        \"UD Ureter-Uterine Artery-Nerve Dataset\",\n",
        "        \"m2caiSeg\",\n",
        "        \"Endoscapes\",\n",
        "        \"Dresden\",\n",
        "        \"CholecSeg8k\"\n",
        "    ]\n",
        "\n",
        "    base_dir = \"/content/drive/MyDrive/CV/SAM2/Datasets\"\n",
        "    eval_results_dir = os.path.join(base_dir, \"Eval_Results\")\n",
        "\n",
        "    # Error log\n",
        "    error_log = []\n",
        "\n",
        "    # Timing logs\n",
        "    timings = {}\n",
        "\n",
        "    # Step 1: Run main_with_finetuned_image_predictor for all datasets\n",
        "    start_time = time.time()\n",
        "    for dataset_name in datasets:\n",
        "        try:\n",
        "            print(f\"Processing dataset: {dataset_name}\")\n",
        "            dataset_start_time = time.time()\n",
        "            main_with_finetuned_image_predictor_parallel(\n",
        "                predictor=predictor,\n",
        "                dataset_name=dataset_name,\n",
        "                dataset_type=dataset_type,\n",
        "                num_points=num_points,\n",
        "                max_workers=threads\n",
        "            )\n",
        "            timings[f\"Processing {dataset_name}\"] = time.time() - dataset_start_time\n",
        "            print(f\"Time taken for processing {dataset_name}: {timings[f'Processing {dataset_name}']:.2f} seconds\")\n",
        "        except Exception as e:\n",
        "            error_message = f\"Error during main_with_finetuned_image_predictor for dataset {dataset_name}: {str(e)}\"\n",
        "            print(error_message)\n",
        "            error_log.append(error_message)\n",
        "    timings[\"Step 1: All Datasets Processing\"] = time.time() - start_time\n",
        "    print(f\"Total time for Step 1 (All Dataset Processing): {timings['Step 1: All Datasets Processing']:.2f} seconds\")\n",
        "\n",
        "    # Step 2: Evaluate results for all datasets\n",
        "    start_time = time.time()\n",
        "    for dataset_name in datasets:\n",
        "        try:\n",
        "            print(f\"Evaluating dataset: {dataset_name}\")\n",
        "            dataset_start_time = time.time()\n",
        "            results_df = evaluate_all_datasets(\n",
        "                base_dir=base_dir,\n",
        "                subset=dataset_type,\n",
        "                datasets=[dataset_name]\n",
        "            )\n",
        "            timings[f\"Evaluating {dataset_name}\"] = time.time() - dataset_start_time\n",
        "            print(f\"Time taken for evaluating {dataset_name}: {timings[f'Evaluating {dataset_name}']:.2f} seconds\")\n",
        "            print(f\"Evaluation complete for dataset: {dataset_name}\")\n",
        "        except Exception as e:\n",
        "            error_message = f\"Error during evaluation for dataset {dataset_name}: {str(e)}\"\n",
        "            print(error_message)\n",
        "            error_log.append(error_message)\n",
        "    timings[\"Step 2: Evaluation\"] = time.time() - start_time\n",
        "    print(f\"Total time for Step 2 (Evaluation): {timings['Step 2: Evaluation']:.2f} seconds\")\n",
        "\n",
        "    # Step 3: Compress and download evaluation results\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        print(\"Compressing and downloading evaluation results...\")\n",
        "        download_all_eval_results(eval_results_dir)\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error during compressing and downloading evaluation results: {str(e)}\"\n",
        "        print(error_message)\n",
        "        error_log.append(error_message)\n",
        "    timings[\"Step 3: Compress and Download Eval Results into csv\"] = time.time() - start_time\n",
        "    print(f\"Total time for Step 3 (Compress and Download Eval Results into csv): {timings['Step 3: Compress and Download Eval Results into csv']:.2f} seconds\")\n",
        "\n",
        "    # Step 4: Compress predicted masks (optional if required)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        print(\"Compressing predicted masks...\")\n",
        "        compress_and_download_predicted_masks(base_dir, datasets, subset=dataset_type)\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error during compressing predicted masks: {str(e)}\"\n",
        "        print(error_message)\n",
        "        error_log.append(error_message)\n",
        "    timings[\"Step 4: Compress Predicted Masks\"] = time.time() - start_time\n",
        "    print(f\"Total time for Step 4 (Compress Predicted Masks): {timings['Step 4: Compress Predicted Masks']:.2f} seconds\")\n",
        "\n",
        "    # Print the error log at the end\n",
        "    if error_log:\n",
        "        print(\"\\n=== Error Log ===\")\n",
        "        for error in error_log:\n",
        "            print(error)\n",
        "    else:\n",
        "        print(\"Pipeline execution complete without errors.\")\n",
        "\n",
        "    # Print timings\n",
        "    print(\"\\n=== Timing Log ===\")\n",
        "    for step, timing in timings.items():\n",
        "        print(f\"{step}: {timing:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HFVGEz1V0YJ"
      },
      "source": [
        "## Loading model checkpoints and running pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ChqVfdQEqzF"
      },
      "outputs": [],
      "source": [
        "## Loading fine-tuned checkpoint weights onto SAM 2\n",
        "checkpoint = \"/content/drive/MyDrive/CV/SAM2/FineTuned_Checkpoints/100/Curated100_checkpoint_20.pt\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
        "\n",
        "sam2_model = build_sam2(model_cfg, checkpoint, device=device)\n",
        "predictor = SAM2ImagePredictor(sam2_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GnpQ3ZvQCgsN"
      },
      "outputs": [],
      "source": [
        "run_pipeline_finetuned_model(num_points=10, dataset_type=\"val\", predictor=predictor, threads=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbq9fmblV8yW"
      },
      "source": [
        "## Clearing masks and eval results zip folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79GhKnX9CoWW"
      },
      "outputs": [],
      "source": [
        "base_dir = \"/content/drive/MyDrive/CV/SAM2/Datasets\"\n",
        "datasets = [\"UD Ureter-Uterine Artery-Nerve Dataset\", \"Dresden\", \"Endoscapes\", \"m2caiSeg\", \"CholecSeg8k\"]\n",
        "eval_results_dir = \"/content/drive/MyDrive/CV/SAM2/Datasets/Eval_Results\"\n",
        "\n",
        "\n",
        "# List of specific zip files to delete\n",
        "zip_files_to_delete_masks = [\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/CholecSeg8k_PredictedMasks.zip\",\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/Dresden_PredictedMasks.zip\",\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/Endoscapes_PredictedMasks.zip\",\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/UDUreter_PredictedMasks.zip\",\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/m2caiSeg_PredictedMasks.zip\",\n",
        "]\n",
        "\n",
        "zip_files_to_delete_eval = [\n",
        "    \"/content/drive/MyDrive/CV/SAM2/Datasets/Eval_Results.zip\"\n",
        "]\n",
        "\n",
        "print(\"Deleting predicted masks zip files...\")\n",
        "delete_zip_files(zip_files_to_delete_masks)\n",
        "\n",
        "print(\"Deleting PredictedMasks folders...\")\n",
        "delete_predicted_masks(base_dir, datasets, subset=\"val\")\n",
        "\n",
        "print(\"Deleting Eval_Results folder...\")\n",
        "delete_eval_results(eval_results_dir)\n",
        "\n",
        "# Delete the zip file\n",
        "delete_zip_files(zip_files_to_delete_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MedSAM inference\n",
        "\n",
        "https://github.com/bowang-lab/MedSAM\n",
        "\n",
        "Finetuned model checkpoint: https://drive.google.com/drive/folders/1ETWmi4AiniJeWOt6HAsYgTjYv_fkgzoN\n",
        "\n",
        "Download \"medsam_vit_b\" from above link \"work_dir/MedSAM/medsam_vit_b\" and Upload onto \"content/medsam_vit_b.pth\""
      ],
      "metadata": {
        "id": "gaQ9oEx608Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/segment-anything.git /content/segment-anything\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1M81dpDong1",
        "outputId": "07fbefbd-7f9b-470c-9863-ac68375aac5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/segment-anything'...\n",
            "remote: Enumerating objects: 304, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 304 (delta 2), reused 1 (delta 1), pack-reused 299 (from 2)\u001b[K\n",
            "Receiving objects: 100% (304/304), 18.31 MiB | 19.86 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download"
      ],
      "metadata": {
        "id": "BX_gFGhHIGWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import SamPredictor\n",
        "from segment_anything import sam_model_registry\n",
        "\n",
        "# Initialize MedSAM model\n",
        "# Define both possible paths\n",
        "path_1 = \"/content/medsam_vit_b.pth\"\n",
        "path_2 = \"/content/drive/MyDrive/CV/SAM2/FineTuned_Checkpoints/MedSAM2_pretrainedCheckpoint/medsam_vit_b\"\n",
        "\n",
        "# Check if path_1 exists, otherwise use path_2\n",
        "MedSAM_CKPT_PATH = path_1 if os.path.exists(path_1) else path_2\n",
        "\n",
        "print(f\"Using checkpoint from: {MedSAM_CKPT_PATH}\")\n",
        "\n",
        "medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
        "medsam_model = medsam_model.to(device)\n",
        "\n",
        "# Create predictor\n",
        "predictor = SamPredictor(medsam_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O--FXrG2R-u",
        "outputId": "139f4954-2589-4d52-b5a0-2c52ed0a1089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/segment_anything/build_sam.py:144: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(f, map_location=torch.device('cpu'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_pipeline_finetuned_model(num_points=10, dataset_type=\"test\", predictor=predictor, threads=32)"
      ],
      "metadata": {
        "id": "xrWKEa3LqIC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical SAM 2\n",
        "\n",
        "https://github.com/bowang-lab/MedSAM/tree/MedSAM2?tab=readme-ov-file#fine-tune-sam2-on-the-abdomen-ct-dataset"
      ],
      "metadata": {
        "id": "oQIiK-SkI2eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUYC_Qi4I74Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "wPzJ0rVcB_uo",
        "gevltrOIIPzL",
        "9gTBtJLW0aja",
        "Q6oiB2ToHSW5",
        "JmhCxbpTVRoe"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}